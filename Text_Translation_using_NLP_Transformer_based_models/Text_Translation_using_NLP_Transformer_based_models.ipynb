{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLoq8X5HkUwz"
   },
   "source": [
    "### <font color = 'purple'> DATA 255: HOMEWORK 09 Transformer Based Text Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQ2PY_SVkUw1"
   },
   "source": [
    "#### <font color = 'purple'> Step1. Run the demo and train a model on the original German-to-English training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T22:33:17.083511Z",
     "iopub.status.busy": "2024-11-15T22:33:17.082568Z",
     "iopub.status.idle": "2024-11-15T22:33:17.087687Z",
     "shell.execute_reply": "2024-11-15T22:33:17.086759Z",
     "shell.execute_reply.started": "2024-11-15T22:33:17.083447Z"
    },
    "id": "DRC7cIA3kUw1",
    "outputId": "06eaf807-1adc-40d7-c4c0-55c16918683b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "pip uninstall -q -y torch torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbC1olTxkUw2"
   },
   "source": [
    "<font color = 'blue'> Downloaded torch and torchtext with versions compatible with each other. Torchtext last version is 0.18.0 is not compatible with latest torch version. So downgrading to torch 2.3.0 to work with torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T22:33:17.090400Z",
     "iopub.status.busy": "2024-11-15T22:33:17.089915Z",
     "iopub.status.idle": "2024-11-15T22:33:17.098748Z",
     "shell.execute_reply": "2024-11-15T22:33:17.097866Z",
     "shell.execute_reply.started": "2024-11-15T22:33:17.090357Z"
    },
    "id": "ftIDlMELkUw2",
    "outputId": "db27fefc-fa8f-4023-9b9a-6a175921ad97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.3.0 which is incompatible.\n",
      "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "pip install -q torch==2.3.0 torchtext==0.18.0 torchdata spacy portalocker==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T22:33:17.100306Z",
     "iopub.status.busy": "2024-11-15T22:33:17.099988Z",
     "iopub.status.idle": "2024-11-15T22:33:17.109382Z",
     "shell.execute_reply": "2024-11-15T22:33:17.108640Z",
     "shell.execute_reply.started": "2024-11-15T22:33:17.100274Z"
    },
    "id": "EeA5e0UykUw2"
   },
   "outputs": [],
   "source": [
    "# !rm -f /kaggle/working/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T22:33:17.111718Z",
     "iopub.status.busy": "2024-11-15T22:33:17.111324Z",
     "iopub.status.idle": "2024-11-15T22:33:17.119689Z",
     "shell.execute_reply": "2024-11-15T22:33:17.118838Z",
     "shell.execute_reply.started": "2024-11-15T22:33:17.111686Z"
    },
    "id": "3jSlZcpakUw2",
    "outputId": "81572aed-864c-48f6-aaa6-2440a5380e40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "0.18.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "print(torch.__version__)\n",
    "print(torchtext.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zUy6z5SkUw3"
   },
   "source": [
    "<font color='blue'> Downloading English language pack using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T22:33:17.121258Z",
     "iopub.status.busy": "2024-11-15T22:33:17.120888Z",
     "iopub.status.idle": "2024-11-15T22:33:33.323442Z",
     "shell.execute_reply": "2024-11-15T22:33:33.322421Z",
     "shell.execute_reply.started": "2024-11-15T22:33:17.121205Z"
    },
    "id": "KQlGnn56kUw3",
    "outputId": "70d312a8-8834-4771-e058-5ba35df0fd28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.13.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96ov07ZSkUw3"
   },
   "source": [
    "<font color='blue'> Downloading German language pack using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T22:33:33.326323Z",
     "iopub.status.busy": "2024-11-15T22:33:33.325975Z",
     "iopub.status.idle": "2024-11-15T22:33:49.545508Z",
     "shell.execute_reply": "2024-11-15T22:33:49.544456Z",
     "shell.execute_reply.started": "2024-11-15T22:33:33.326288Z"
    },
    "id": "xn6gZU5CkUw3",
    "outputId": "1a8f063e-93a0-49e1-b9ec-36ee9d6e6d86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.13.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.7.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LddQ4G7XkUw3"
   },
   "source": [
    "<font color='blue'> Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T22:33:49.547738Z",
     "iopub.status.busy": "2024-11-15T22:33:49.546997Z",
     "iopub.status.idle": "2024-11-15T22:33:49.553825Z",
     "shell.execute_reply": "2024-11-15T22:33:49.552821Z",
     "shell.execute_reply.started": "2024-11-15T22:33:49.547700Z"
    },
    "id": "INZK4Op4kUw3",
    "outputId": "904dbe9d-a772-4481-d87e-54cb9b3390c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/usr/local/lib/python3.10/dist-packages/torchtext/datasets/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T22:33:49.555520Z",
     "iopub.status.busy": "2024-11-15T22:33:49.555127Z",
     "iopub.status.idle": "2024-11-15T22:33:49.565248Z",
     "shell.execute_reply": "2024-11-15T22:33:49.564303Z",
     "shell.execute_reply.started": "2024-11-15T22:33:49.555454Z"
    },
    "id": "uA6QeviqkUw3"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udu5Tu1ikUw3"
   },
   "source": [
    "<font color='blue'> Setting up train and validation dataset using Multi30K dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T22:33:49.566625Z",
     "iopub.status.busy": "2024-11-15T22:33:49.566331Z",
     "iopub.status.idle": "2024-11-15T22:33:49.579897Z",
     "shell.execute_reply": "2024-11-15T22:33:49.578972Z",
     "shell.execute_reply.started": "2024-11-15T22:33:49.566595Z"
    },
    "id": "SzlRA0TZkUw4"
   },
   "outputs": [],
   "source": [
    "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "\n",
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'\n",
    "\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00tozg2YkUw4"
   },
   "source": [
    "<font color='blue'> Initializing tokenizers for English and German Languages and builing vocabulary for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T22:33:49.581733Z",
     "iopub.status.busy": "2024-11-15T22:33:49.581256Z",
     "iopub.status.idle": "2024-11-15T22:33:58.315790Z",
     "shell.execute_reply": "2024-11-15T22:33:58.314726Z",
     "shell.execute_reply.started": "2024-11-15T22:33:49.581688Z"
    },
    "id": "cv3jlgPWkUw4",
    "outputId": "c4c15195-302b-46c1-fb52-d25ae10cb9cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchdata/datapipes/__init__.py:18: UserWarning: \n",
      "################################################################################\n",
      "WARNING!\n",
      "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
      "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
      "to learn more and leave feedback.\n",
      "################################################################################\n",
      "\n",
      "  deprecation_warning()\n"
     ]
    }
   ],
   "source": [
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "# special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "\n",
    "# Setting UNK_IDX as the default index.\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "  vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T22:33:58.319450Z",
     "iopub.status.busy": "2024-11-15T22:33:58.319123Z",
     "iopub.status.idle": "2024-11-15T22:33:58.336584Z",
     "shell.execute_reply": "2024-11-15T22:33:58.335602Z",
     "shell.execute_reply.started": "2024-11-15T22:33:58.319417Z"
    },
    "id": "9FsIX4JskUw4"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hs4PDyWLkUw4"
   },
   "source": [
    "<font color='blue'> Defining the transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "O7Gs9lDjkUw4"
   },
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T22:33:58.337913Z",
     "iopub.status.busy": "2024-11-15T22:33:58.337606Z",
     "iopub.status.idle": "2024-11-15T22:33:58.354235Z",
     "shell.execute_reply": "2024-11-15T22:33:58.353263Z",
     "shell.execute_reply.started": "2024-11-15T22:33:58.337883Z"
    },
    "id": "JwnxJNH5kUw4"
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dd_D3s2skUw4"
   },
   "source": [
    "<font color='blue'> Initialize the Model, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T22:33:58.355732Z",
     "iopub.status.busy": "2024-11-15T22:33:58.355333Z",
     "iopub.status.idle": "2024-11-15T22:34:00.252274Z",
     "shell.execute_reply": "2024-11-15T22:34:00.251301Z",
     "shell.execute_reply.started": "2024-11-15T22:33:58.355688Z"
    },
    "id": "6c125ErdkUw4",
    "outputId": "60e7a44e-5a9f-45ce-e406-1d8b27a85b90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer_de_en = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer_de_en.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer_de_en = transformer_de_en.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer_de_en.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T22:34:00.254054Z",
     "iopub.status.busy": "2024-11-15T22:34:00.253458Z",
     "iopub.status.idle": "2024-11-15T22:34:00.262734Z",
     "shell.execute_reply": "2024-11-15T22:34:00.261622Z",
     "shell.execute_reply.started": "2024-11-15T22:34:00.254016Z"
    },
    "id": "SWT80tJIkUw5"
   },
   "outputs": [],
   "source": [
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln],\n",
    "                                               vocab_transform[ln],\n",
    "                                               tensor_transform)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqLLtXTzkUw5"
   },
   "source": [
    "<font color='blue'> Function for the training and evaluation batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T22:34:00.264185Z",
     "iopub.status.busy": "2024-11-15T22:34:00.263873Z",
     "iopub.status.idle": "2024-11-15T22:34:00.280089Z",
     "shell.execute_reply": "2024-11-15T22:34:00.279199Z",
     "shell.execute_reply.started": "2024-11-15T22:34:00.264154Z"
    },
    "id": "z4fFqLg2kUw5"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in train_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuvK_Q6JkUw5"
   },
   "source": [
    "<font color='blue'> Train the Model and evaluate the model's performance on validation batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T22:34:00.281458Z",
     "iopub.status.busy": "2024-11-15T22:34:00.281161Z",
     "iopub.status.idle": "2024-11-15T22:50:39.430253Z",
     "shell.execute_reply": "2024-11-15T22:50:39.429224Z",
     "shell.execute_reply.started": "2024-11-15T22:34:00.281427Z"
    },
    "id": "_XTHAlqmkUw5",
    "outputId": "b062d532-7986-49a2-e4cf-f5a544bd9503"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 5.344, Val loss: 4.107, Epoch time = 42.197s\n",
      "Epoch: 2, Train loss: 3.760, Val loss: 3.309, Epoch time = 41.990s\n",
      "Epoch: 3, Train loss: 3.157, Val loss: 2.886, Epoch time = 43.635s\n",
      "Epoch: 4, Train loss: 2.767, Val loss: 2.639, Epoch time = 44.950s\n",
      "Epoch: 5, Train loss: 2.477, Val loss: 2.439, Epoch time = 44.069s\n",
      "Epoch: 6, Train loss: 2.247, Val loss: 2.305, Epoch time = 45.216s\n",
      "Epoch: 7, Train loss: 2.055, Val loss: 2.208, Epoch time = 44.058s\n",
      "Epoch: 8, Train loss: 1.893, Val loss: 2.114, Epoch time = 44.184s\n",
      "Epoch: 9, Train loss: 1.754, Val loss: 2.053, Epoch time = 45.254s\n",
      "Epoch: 10, Train loss: 1.628, Val loss: 2.007, Epoch time = 43.996s\n",
      "Epoch: 11, Train loss: 1.519, Val loss: 1.961, Epoch time = 44.807s\n",
      "Epoch: 12, Train loss: 1.419, Val loss: 1.955, Epoch time = 44.723s\n",
      "Epoch: 13, Train loss: 1.330, Val loss: 1.969, Epoch time = 44.051s\n",
      "Epoch: 14, Train loss: 1.245, Val loss: 1.973, Epoch time = 44.925s\n",
      "Epoch: 15, Train loss: 1.173, Val loss: 1.931, Epoch time = 44.281s\n",
      "Epoch: 16, Train loss: 1.103, Val loss: 1.895, Epoch time = 44.175s\n",
      "Epoch: 17, Train loss: 1.036, Val loss: 1.907, Epoch time = 44.998s\n",
      "Epoch: 18, Train loss: 0.974, Val loss: 1.929, Epoch time = 44.111s\n",
      "Epoch: 19, Train loss: 0.919, Val loss: 1.948, Epoch time = 44.235s\n",
      "Epoch: 20, Train loss: 0.866, Val loss: 1.944, Epoch time = 45.156s\n",
      "Epoch: 21, Train loss: 0.815, Val loss: 1.934, Epoch time = 44.081s\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 21\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer_de_en, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer_de_en)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "def translate(model: torch.nn.Module, src_sentence: str, SRC_LANG: str, TGT_LANG: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANG](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANG].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlEXLfRlkUw5"
   },
   "source": [
    "<font color = 'blue'> From the model performance, we see that there is a consistent decrease in training loss across all epochs indicating that the model is learning the patterns in the training data effectively. Whereas validation loss improves significantly until epoch 16, where it starts to plateau and slightly increase or fluctuate which suggests potential overfitting. The best performance we see at around epoch 16 (Val loss: 1.895). We can consider early stopping at this point to avoid overfitting.\n",
    "\n",
    "<font color = 'blue'> We will see a few examples on how the model is translating text from German to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T22:50:39.432295Z",
     "iopub.status.busy": "2024-11-15T22:50:39.431849Z",
     "iopub.status.idle": "2024-11-15T22:50:39.531842Z",
     "shell.execute_reply": "2024-11-15T22:50:39.530778Z",
     "shell.execute_reply.started": "2024-11-15T22:50:39.432246Z"
    },
    "id": "QXprv86wkUw5",
    "outputId": "41d461ef-6142-4f0c-9766-5e9914ad5a8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A group of people standing in front of an igloo \n"
     ]
    }
   ],
   "source": [
    "print(translate(transformer_de_en,\n",
    "                \"Eine Gruppe von Menschen steht vor einem Iglu .\",\n",
    "                SRC_LANGUAGE,\n",
    "                TGT_LANGUAGE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8ROPQ4RkUw5"
   },
   "source": [
    "<font color = 'blue'> Calling the translate function with the parameters as model, text and the source language and target language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T22:50:39.533628Z",
     "iopub.status.busy": "2024-11-15T22:50:39.533264Z",
     "iopub.status.idle": "2024-11-15T22:50:39.617372Z",
     "shell.execute_reply": "2024-11-15T22:50:39.616310Z",
     "shell.execute_reply.started": "2024-11-15T22:50:39.533592Z"
    },
    "id": "kgCG8S97kUw6",
    "outputId": "2431908f-542d-4165-b837-fddb3c7cdd8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A boy with headphones is sitting on a woman 's shoulders . \n"
     ]
    }
   ],
   "source": [
    "print(translate(transformer_de_en,\n",
    "                \"Ein Junge mit Kopfhörern sitzt auf den Schultern einer Frau.\",\n",
    "                SRC_LANGUAGE,\n",
    "                TGT_LANGUAGE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFqySXrHkUw6"
   },
   "source": [
    "<font color = 'blue'> Saving the model state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T22:50:39.619613Z",
     "iopub.status.busy": "2024-11-15T22:50:39.619241Z",
     "iopub.status.idle": "2024-11-15T22:50:39.863900Z",
     "shell.execute_reply": "2024-11-15T22:50:39.863029Z",
     "shell.execute_reply.started": "2024-11-15T22:50:39.619575Z"
    },
    "id": "qkEgxwwskUw6"
   },
   "outputs": [],
   "source": [
    "torch.save(transformer_de_en.state_dict(), \"transformer_de_en.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZ7wmqXqkUw6"
   },
   "source": [
    "#### <font color = 'purple'>Step2. Train a New model of the same architecture on the opposite training set (English-to-German)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uaPHc1DkUw6"
   },
   "source": [
    "<font color = 'blue'>Training a new model on the same architecture for English-to-German Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ZZ8_T8L9kUw6"
   },
   "outputs": [],
   "source": [
    "SRC_LANGUAGE = 'en'\n",
    "TGT_LANGUAGE = 'de'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAvapbXckUw6"
   },
   "source": [
    "<font color = 'blue'> Resetting token and vocabulary transformations for new language direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r08ZWHuHkUw_",
    "outputId": "84d90567-896c-40cb-ec08-889e91e9a4b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
      "  warnings.warn(Warnings.W111)\n"
     ]
    }
   ],
   "source": [
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "FkJdd99ckUxA"
   },
   "outputs": [],
   "source": [
    "vocab_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # new language pair in Multi30k dataset\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nq2LE5InkUxA"
   },
   "source": [
    "<font color = 'blue'> Initializing and configuring the Seq2SeqTransformer for English-to-German training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUEUcuwUkUxA",
    "outputId": "4b4a8f81-af1e-498b-dbd4-2bb559df212f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "\n",
    "transformer_en_de = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM).to(DEVICE)\n",
    "\n",
    "for p in transformer_en_de.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer_en_de.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QISguwD6kUxA"
   },
   "source": [
    "<font color = 'blue'> Redefining the text transformation for the new source-target languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "h3-Hve4AkUxA"
   },
   "outputs": [],
   "source": [
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln],\n",
    "                                               vocab_transform[ln],\n",
    "                                               tensor_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vY2Sq8YkUxA"
   },
   "source": [
    "<font color = 'blue'> Training the model with the English-to-German dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T22:50:39.865479Z",
     "iopub.status.busy": "2024-11-15T22:50:39.865143Z",
     "iopub.status.idle": "2024-11-15T23:10:12.437414Z",
     "shell.execute_reply": "2024-11-15T23:10:12.436509Z",
     "shell.execute_reply.started": "2024-11-15T22:50:39.865432Z"
    },
    "id": "nZ78ePyhkUxA",
    "outputId": "25765113-8e35-44ad-f709-2e4ab58256ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 5.881, Val loss: 4.637, Epoch time = 51.660s\n",
      "Epoch: 2, Train loss: 4.125, Val loss: 3.778, Epoch time = 51.197s\n",
      "Epoch: 3, Train loss: 3.460, Val loss: 3.318, Epoch time = 51.532s\n",
      "Epoch: 4, Train loss: 3.028, Val loss: 3.025, Epoch time = 52.579s\n",
      "Epoch: 5, Train loss: 2.707, Val loss: 2.815, Epoch time = 51.784s\n",
      "Epoch: 6, Train loss: 2.451, Val loss: 2.667, Epoch time = 51.463s\n",
      "Epoch: 7, Train loss: 2.243, Val loss: 2.527, Epoch time = 51.646s\n",
      "Epoch: 8, Train loss: 2.063, Val loss: 2.414, Epoch time = 51.915s\n",
      "Epoch: 9, Train loss: 1.910, Val loss: 2.326, Epoch time = 52.694s\n",
      "Epoch: 10, Train loss: 1.778, Val loss: 2.267, Epoch time = 51.755s\n",
      "Epoch: 11, Train loss: 1.660, Val loss: 2.219, Epoch time = 51.796s\n",
      "Epoch: 12, Train loss: 1.553, Val loss: 2.173, Epoch time = 51.707s\n",
      "Epoch: 13, Train loss: 1.453, Val loss: 2.154, Epoch time = 52.734s\n",
      "Epoch: 14, Train loss: 1.363, Val loss: 2.151, Epoch time = 52.359s\n",
      "Epoch: 15, Train loss: 1.288, Val loss: 2.118, Epoch time = 51.714s\n",
      "Epoch: 16, Train loss: 1.212, Val loss: 2.066, Epoch time = 51.496s\n",
      "Epoch: 17, Train loss: 1.140, Val loss: 2.041, Epoch time = 52.611s\n",
      "Epoch: 18, Train loss: 1.076, Val loss: 2.047, Epoch time = 52.652s\n",
      "Epoch: 19, Train loss: 1.016, Val loss: 2.069, Epoch time = 51.756s\n",
      "Epoch: 20, Train loss: 0.959, Val loss: 2.073, Epoch time = 51.655s\n",
      "Epoch: 21, Train loss: 0.904, Val loss: 2.075, Epoch time = 51.988s\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 21\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer_en_de, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer_en_de)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"\n",
    "           f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOntE2D-kUxA"
   },
   "source": [
    "<font color = 'blue'> The training process for the English-to-German Transformer model shows steady progress, with training loss and validation loss decreasing over the epochs which indicates effective learning. By epoch 16, the validation loss reaches its minimum value of 2.060, suggesting this is the point of optimal performance. Later, the validation loss begins to plateau and slightly increase, with minimal improvements in validation performance. This suggests same that the model is starting to overfit the training data after 16th epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:10:12.439401Z",
     "iopub.status.busy": "2024-11-15T23:10:12.439009Z",
     "iopub.status.idle": "2024-11-15T23:10:12.720744Z",
     "shell.execute_reply": "2024-11-15T23:10:12.719723Z",
     "shell.execute_reply.started": "2024-11-15T23:10:12.439357Z"
    },
    "id": "WUGROUHgkUxA"
   },
   "outputs": [],
   "source": [
    "torch.save(transformer_en_de.state_dict(), \"transformer_en_de.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mesVM57-kUxA"
   },
   "source": [
    "<font color = 'blue'> Calling the translate function with the parameters as model, text and the source language and target language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T23:10:12.722319Z",
     "iopub.status.busy": "2024-11-15T23:10:12.722022Z",
     "iopub.status.idle": "2024-11-15T23:10:12.778528Z",
     "shell.execute_reply": "2024-11-15T23:10:12.777647Z",
     "shell.execute_reply.started": "2024-11-15T23:10:12.722288Z"
    },
    "id": "CID5wPYTkUxA",
    "outputId": "a73f48b9-852d-4363-fbff-8cabd08120cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Eine Gruppe von Menschen steht vor einem Iglu . \n"
     ]
    }
   ],
   "source": [
    "print(translate(transformer_en_de,\n",
    "                \"A group of people stands in front of an igloo.\",\n",
    "                SRC_LANGUAGE,\n",
    "                TGT_LANGUAGE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiU9nVLokUxA"
   },
   "source": [
    "#### <font color = 'purple'>Step3. Insert novel sentences into your English-to-German model. Take the output and feed it to the original German-to-English model. Observe and report qualitatively on the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjPj5MeukUxB"
   },
   "source": [
    "<font color = 'blue'> Sample sentences to test the English-to-German and back-translated German-to-English pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Z5IiixAEkUxB"
   },
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"The cat is sleeping on the couch.\",\n",
    "    \"A man is riding a bicycle through the park.\",\n",
    "    \"The sky is clear, and the sun is shining brightly.\",\n",
    "    \"She is reading a book in the library.\",\n",
    "    \"A child is playing with a ball on the beach.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONPhkGrdkUxB"
   },
   "source": [
    "<font color = 'blue'> First, translate from English to German using the English-to-German model in step-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXUbx9XvkUxB",
    "outputId": "0cba4cec-423c-432d-9ad5-e38424539eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English to German: 'The cat is sleeping on the couch.' -> ' Die Katze schläft auf dem Sofa . '\n",
      "English to German: 'A man is riding a bicycle through the park.' -> ' Ein Mann fährt mit einem Fahrrad durch den Park . '\n",
      "English to German: 'The sky is clear, and the sun is shining brightly.' -> ' Der Himmel ist klaren , die Sonne gekleidet ist , und die Sonne scheint . '\n",
      "English to German: 'She is reading a book in the library.' -> ' Sie liest ein Buch in der Bibliothek . '\n",
      "English to German: 'A child is playing with a ball on the beach.' -> ' Ein Kind spielt am Strand mit einem Ball . '\n"
     ]
    }
   ],
   "source": [
    "translated_sentences = []\n",
    "for sentence in test_sentences:\n",
    "    german_translation = translate(transformer_en_de, sentence, 'en', 'de')\n",
    "    translated_sentences.append(german_translation)\n",
    "    print(f\"English to German: '{sentence}' -> '{german_translation}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw3Syb-9kUxB"
   },
   "source": [
    "<font color = 'blue'> Now, take the German translations and translate back to English using the German-to-English model in step-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-15T23:10:12.780449Z",
     "iopub.status.busy": "2024-11-15T23:10:12.780034Z",
     "iopub.status.idle": "2024-11-15T23:10:13.335991Z",
     "shell.execute_reply": "2024-11-15T23:10:13.335039Z",
     "shell.execute_reply.started": "2024-11-15T23:10:12.780402Z"
    },
    "id": "5-SOA1h-kUxB",
    "outputId": "893662e2-f4a6-4837-dd85-ea8edec2d35c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- German to English (Back-translation) ---\n",
      "Original: 'The cat is sleeping on the couch.'\n",
      "German Translation: ' Die Katze schläft auf dem Sofa . '\n",
      "Back to English: ' The cat is sleeping on the couch . '\n",
      "\n",
      "Original: 'A man is riding a bicycle through the park.'\n",
      "German Translation: ' Ein Mann fährt mit einem Fahrrad durch den Park . '\n",
      "Back to English: ' A man is riding a bicycle through the park . '\n",
      "\n",
      "Original: 'The sky is clear, and the sun is shining brightly.'\n",
      "German Translation: ' Der Himmel ist klaren , die Sonne gekleidet ist , und die Sonne scheint . '\n",
      "Back to English: ' There are the sun , the sun , dressed in the sun , and the sun . '\n",
      "\n",
      "Original: 'She is reading a book in the library.'\n",
      "German Translation: ' Sie liest ein Buch in der Bibliothek . '\n",
      "Back to English: ' It is reading a book in the library . '\n",
      "\n",
      "Original: 'A child is playing with a ball on the beach.'\n",
      "German Translation: ' Ein Kind spielt am Strand mit einem Ball . '\n",
      "Back to English: ' A child playing with a ball on a beach . '\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- German to English (Back-translation) ---\")\n",
    "for original, german_sentence in zip(test_sentences, translated_sentences):\n",
    "    back_translation = translate(transformer_de_en, german_sentence, 'de', 'en')\n",
    "    print(f\"Original: '{original}'\")\n",
    "    print(f\"German Translation: '{german_sentence}'\")\n",
    "    print(f\"Back to English: '{back_translation}'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2JSwn_0kUxB"
   },
   "source": [
    "<font color = 'blue'> The results of the English-to-German and back-translation to English shows mixed performance. For some sentences, the model successfully captures the meaning and structure during the forward and backward translations whereas for others, inaccuracies or semantic shifts do occur.\n",
    "\n",
    "<font color = 'blue'> <b> High-quality translations:\n",
    "\n",
    "<font color = 'blue'> Sentences like \"The cat is sleeping on the couch.\" and \"A man is riding a bicycle through the park.\" are accurately translated to German and back to English indicating model is able to handle straightforward sentences with simple syntax.\n",
    "\n",
    "<font color = 'blue'><b> Moderate-quality translations:\n",
    "\n",
    "<font color = 'blue'>In \"A child is playing with a ball on the beach.\", the back-translated sentence slightly deviates from the original by dropping the article \"A\" before \"child\" in the English reconstruction. However, the overall meaning was preserved.\n",
    "\n",
    "<font color = 'blue'><b> Low-quality translations:\n",
    "\n",
    "<font color = 'blue'>\n",
    "The sentence \"The sky is clear, and the sun is shining brightly.\" undergo significant distortion during back-translation. Phrases like \"This sun is dressed in the sky\" do not capture coherence suggesting model is struggling to translate complex sentences. Similarly \"She is reading a book in the library.\" was back-translated incorrectly as \"It is a book reading a book in the library,\" indicating challenges with pronouns and verbs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khkyf3TBkUxB"
   },
   "source": [
    "<font color = 'blue'>  The model handles simple declarative sentences well, maintaining translation consistency and demonstrating a solid grasp of basic structure and vocabulary but struggles with complex sentences, showing limitations in understanding nuanced relationships\n",
    "\n",
    "<font color = 'blue'>  Further fine-tuning of the models on a dataset with diverse sentence structures could help address these challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1itEG2zkkUxB"
   },
   "source": [
    "## <font color = 'blue'> Thank You!!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
